{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CLIENT_ID = 'fa9f3d44584944cf8cd7d988ffe47c6d'\n",
    "CLIENT_SECRET = '2de72e647f51489b80408089da9080eb'\n",
    "\n",
    "SPOTIFY_TOKEN_URL = \"https://accounts.spotify.com/api/token\"\n",
    "SPOTIFY_SEARCH_URL = \"https://api.spotify.com/v1/search\"\n",
    "\n",
    "\n",
    "def get_access_token(client_id, client_secret):\n",
    "    client_creds = f\"{client_id}:{client_secret}\"\n",
    "    client_creds_b64 = base64.b64encode(client_creds.encode())\n",
    "\n",
    "    token_data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    token_headers = {\n",
    "        'Authorization': f'Basic {client_creds_b64.decode()}'\n",
    "    }\n",
    "\n",
    "    r = requests.post(SPOTIFY_TOKEN_URL, data=token_data,\n",
    "                      headers=token_headers)\n",
    "    token_response_data = r.json()\n",
    "    \n",
    "    return token_response_data.get('access_token')\n",
    "\n",
    "access_token = get_access_token(CLIENT_ID, CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_albums(access_token, offset=0):\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "    search_params = {\n",
    "        'q': 'tag:new',\n",
    "        'type': 'album',\n",
    "        'limit': 50,\n",
    "        'offset': offset\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\"https://api.spotify.com/v1/search\", headers=headers, params=search_params)\n",
    "    \n",
    "    if response.ok:\n",
    "        results = response.json()['albums']['items']\n",
    "        return results\n",
    "\n",
    "    return response.status_code\n",
    "\n",
    "def get_album_details(access_token, album_ids:list):\n",
    "    url = f\"https://api.spotify.com/v1/albums?ids={','.join(album_ids)}\"\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_artist_genres(access_token, artist_id):\n",
    "    url = f\"https://api.spotify.com/v1/artists/{artist_id}\"\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json().get('genres', [])\n",
    "\n",
    "\n",
    "def get_album_artists(access_token, album_id):\n",
    "    url = f\"https://api.spotify.com/v1/albums/{album_id}\"\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    album_data = response.json()\n",
    "    artist_ids = [artist['id'] for artist in album_data['artists']]\n",
    "    return artist_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_songs(access_token, offset):\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "    search_params = {\n",
    "        # 'q': 'tag:new',\n",
    "        'type': 'track',\n",
    "        'limit': 50,\n",
    "        'offset': offset\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\"https://api.spotify.com/v1/search\", headers=headers, params=search_params)\n",
    "    \n",
    "    if response.ok:\n",
    "        results = response.json()['tracks']['items']\n",
    "        return results\n",
    "\n",
    "    return response.status_code\n",
    "\n",
    "\n",
    "def get_song_features(access_token, track_ids):\n",
    "    features_url = f\"https://api.spotify.com/v1/audio-features?ids={','.join(track_ids)}\"\n",
    "    header = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    res = requests.get(features_url, headers=header)\n",
    "    return res.json()\n",
    "\n",
    "\n",
    "def map_key_to_pitch_class(key):\n",
    "    key_map = {\n",
    "        -1: \"\",\n",
    "        0: \"C\",\n",
    "        1: \"C#\",\n",
    "        2: \"D\",\n",
    "        3: \"D#\",\n",
    "        4: \"E\",\n",
    "        5: \"F\",\n",
    "        6: \"F#\",\n",
    "        7: \"G\",\n",
    "        8: \"G#\",\n",
    "        9: \"A\",\n",
    "        10: \"A#\",\n",
    "        11: \"B\"\n",
    "    }\n",
    "    return key_map.get(key, \"\")\n",
    "\n",
    "\n",
    "def map_mode_to_name(mode):\n",
    "    mode_map = {\n",
    "        0: \"Minor\",\n",
    "        1: \"Major\"\n",
    "    }\n",
    "    return mode_map.get(mode, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "all_new_songs = pd.DataFrame()\n",
    "offset = 0\n",
    "\n",
    "while len(all_new_songs) < 2000:\n",
    "    songs = fetch_songs(access_token, offset=offset)\n",
    "    song_ids = [song[\"id\"] for song in songs]\n",
    "\n",
    "    song_details = []\n",
    "    for chunk in [song_ids[x:x+20] for x in range(0, len(song_ids), 20)]:\n",
    "        details = get_song_features(access_token, chunk)['audio_features']\n",
    "\n",
    "        for i, song_id in enumerate(chunk):\n",
    "            song_info = songs[i]\n",
    "            detail = details[i]  \n",
    "\n",
    "            # if song_info[\"popularity\"] > 50: #long tail\n",
    "            #     continue\n",
    "\n",
    "            if detail is not None and song_info is not None:\n",
    "                merged_song_detail = {**song_info, **detail}\n",
    "                song_details.append(merged_song_detail)\n",
    "\n",
    "    print(len(all_new_songs) + len(song_details))\n",
    "\n",
    "    songs_df = pd.DataFrame([{\n",
    "        'track_name': song.get('name', ''),\n",
    "        'artist(s)_name': \", \".join([artist['name'] for artist in song['artists']]),\n",
    "        'artist_count': len(song.get('artists')),\n",
    "        'album': song.get('album', {}).get('name', \"\"),\n",
    "        'explicit': song.get('explicit', ''),\n",
    "        'popularity': song.get('popularity', np.NaN),\n",
    "        'release_date': song.get('album', {}).get('release_date', \"\"),\n",
    "        'streams': np.NaN,\n",
    "        'duration_in_min': song.get('duration_ms', np.NaN) / 60000,\n",
    "        'bpm': math.floor(song.get('tempo', np.NaN)),\n",
    "        'key': map_key_to_pitch_class(song.get('key', -1)),\n",
    "        'mode': map_mode_to_name(song.get('mode', np.NaN)),\n",
    "        'danceability_%': math.ceil(song.get('danceability', np.NaN) * 100),\n",
    "        'valence_%': math.ceil(song.get('valence', np.NaN) * 100),\n",
    "        'energy_%': math.ceil(song.get('energy', np.NaN) * 100),\n",
    "        'acousticness_%': math.ceil(song.get('acousticness', np.NaN) * 100),\n",
    "        'instrumentalness_%': math.ceil(song.get('instrumentalness', np.NaN) * 100),\n",
    "        'liveness_%': math.ceil(song.get('liveness', np.NaN) * 100),\n",
    "        'speechiness_%': math.ceil(song.get('speechiness', np.NaN) * 100),\n",
    "    } for song in song_details])\n",
    "\n",
    "    all_new_songs = pd.concat(\n",
    "        [all_new_songs, songs_df], ignore_index=True)\n",
    "\n",
    "    time.sleep(1)\n",
    "    offset += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_songs.head(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "all_new_albums = pd.DataFrame()\n",
    "offset = 0\n",
    "\n",
    "song_ids = []\n",
    "\n",
    "while len(all_new_albums) < 5000:\n",
    "    new_albums = fetch_albums(access_token, offset=offset)\n",
    "\n",
    "    new_album_ids = [album[\"id\"] for album in new_albums]\n",
    "\n",
    "    new_album_details = []\n",
    "    for chunk in [new_album_ids[x:x+20] for x in range(0, len(new_album_ids), 20)]:\n",
    "        album_details = get_album_details(access_token, chunk)['albums'] \n",
    "        \n",
    "        for album in album_details:\n",
    "            \n",
    "            print(album)\n",
    "            \n",
    "            if album[\"album_type\"] == \"album\":\n",
    "                artist_ids = get_album_artists(access_token, album[\"id\"])\n",
    "                genres = []\n",
    "                \n",
    "                for artist_id in artist_ids:\n",
    "                    genres += get_artist_genres(access_token, artist_id)\n",
    "                    \n",
    "                album[\"genres\"] = list(set(genres))\n",
    "                new_album_details.append(album)\n",
    "                \n",
    "                song_ids += [song[\"id\"]for song in album[\"tracks\"][\"items\"]]\n",
    "\n",
    "    print(len(all_new_albums) + len(new_album_details))\n",
    "\n",
    "    new_albums_df = pd.DataFrame([{\n",
    "        'album_name': album['name'],\n",
    "        'artist_name': \", \".join([artist[\"name\"] for artist in album['artists']]),\n",
    "        'release_date': album['release_date'],\n",
    "        'genres': \", \".join(album['genres']),\n",
    "        'descriptors': \"\",\n",
    "        'avg_rating': np.NaN,\n",
    "        'rating_count': np.NaN,\n",
    "        'review_count': np.NaN,\n",
    "        'popularity': album['popularity'],\n",
    "        'total_tracks': album['total_tracks'],\n",
    "    } for album in new_album_details])\n",
    "\n",
    "    all_new_albums = pd.concat(\n",
    "        [all_new_albums, new_albums_df], ignore_index=True)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    offset += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 497\n",
      "1 of 497\n",
      "2 of 497\n",
      "3 of 497\n",
      "4 of 497\n",
      "5 of 497\n",
      "6 of 497\n",
      "7 of 497\n",
      "8 of 497\n",
      "9 of 497\n",
      "10 of 497\n",
      "11 of 497\n",
      "12 of 497\n",
      "13 of 497\n",
      "14 of 497\n",
      "15 of 497\n",
      "16 of 497\n",
      "17 of 497\n",
      "18 of 497\n",
      "19 of 497\n",
      "20 of 497\n",
      "21 of 497\n",
      "22 of 497\n",
      "23 of 497\n",
      "24 of 497\n",
      "25 of 497\n",
      "26 of 497\n",
      "27 of 497\n",
      "28 of 497\n",
      "29 of 497\n",
      "30 of 497\n",
      "31 of 497\n",
      "32 of 497\n",
      "33 of 497\n",
      "34 of 497\n",
      "35 of 497\n",
      "36 of 497\n",
      "37 of 497\n",
      "38 of 497\n",
      "39 of 497\n",
      "40 of 497\n",
      "41 of 497\n",
      "42 of 497\n",
      "43 of 497\n",
      "44 of 497\n",
      "45 of 497\n",
      "46 of 497\n",
      "47 of 497\n",
      "48 of 497\n",
      "49 of 497\n",
      "50 of 497\n",
      "51 of 497\n",
      "52 of 497\n",
      "53 of 497\n",
      "54 of 497\n",
      "55 of 497\n",
      "56 of 497\n",
      "57 of 497\n",
      "58 of 497\n",
      "59 of 497\n",
      "60 of 497\n",
      "61 of 497\n",
      "62 of 497\n",
      "63 of 497\n",
      "64 of 497\n",
      "65 of 497\n",
      "66 of 497\n",
      "67 of 497\n",
      "68 of 497\n",
      "69 of 497\n",
      "70 of 497\n",
      "71 of 497\n",
      "72 of 497\n",
      "73 of 497\n",
      "74 of 497\n",
      "75 of 497\n",
      "76 of 497\n",
      "77 of 497\n",
      "78 of 497\n",
      "79 of 497\n",
      "80 of 497\n",
      "81 of 497\n",
      "82 of 497\n",
      "83 of 497\n",
      "84 of 497\n",
      "85 of 497\n",
      "86 of 497\n",
      "87 of 497\n",
      "88 of 497\n",
      "89 of 497\n",
      "90 of 497\n",
      "91 of 497\n",
      "92 of 497\n",
      "93 of 497\n",
      "94 of 497\n",
      "95 of 497\n",
      "96 of 497\n",
      "97 of 497\n",
      "98 of 497\n",
      "99 of 497\n",
      "100 of 497\n",
      "101 of 497\n",
      "102 of 497\n",
      "103 of 497\n",
      "104 of 497\n",
      "105 of 497\n",
      "106 of 497\n",
      "107 of 497\n",
      "108 of 497\n",
      "109 of 497\n",
      "110 of 497\n",
      "111 of 497\n",
      "112 of 497\n",
      "113 of 497\n",
      "114 of 497\n",
      "115 of 497\n",
      "116 of 497\n",
      "117 of 497\n",
      "118 of 497\n",
      "119 of 497\n",
      "120 of 497\n",
      "121 of 497\n",
      "122 of 497\n",
      "123 of 497\n",
      "124 of 497\n",
      "125 of 497\n",
      "126 of 497\n",
      "127 of 497\n",
      "128 of 497\n",
      "129 of 497\n",
      "130 of 497\n",
      "131 of 497\n",
      "132 of 497\n",
      "133 of 497\n",
      "134 of 497\n",
      "135 of 497\n",
      "136 of 497\n",
      "137 of 497\n",
      "138 of 497\n",
      "139 of 497\n",
      "140 of 497\n",
      "141 of 497\n",
      "142 of 497\n",
      "143 of 497\n",
      "144 of 497\n",
      "145 of 497\n",
      "146 of 497\n",
      "147 of 497\n",
      "148 of 497\n",
      "149 of 497\n",
      "150 of 497\n",
      "151 of 497\n",
      "152 of 497\n",
      "153 of 497\n",
      "154 of 497\n",
      "155 of 497\n",
      "156 of 497\n",
      "157 of 497\n",
      "158 of 497\n",
      "159 of 497\n",
      "160 of 497\n",
      "161 of 497\n",
      "162 of 497\n",
      "163 of 497\n",
      "164 of 497\n",
      "165 of 497\n",
      "166 of 497\n",
      "167 of 497\n",
      "168 of 497\n",
      "169 of 497\n",
      "170 of 497\n",
      "171 of 497\n",
      "172 of 497\n",
      "173 of 497\n",
      "174 of 497\n",
      "175 of 497\n",
      "176 of 497\n",
      "177 of 497\n",
      "178 of 497\n",
      "179 of 497\n",
      "180 of 497\n",
      "181 of 497\n",
      "182 of 497\n",
      "183 of 497\n",
      "184 of 497\n",
      "185 of 497\n",
      "186 of 497\n",
      "187 of 497\n",
      "188 of 497\n",
      "189 of 497\n",
      "190 of 497\n",
      "191 of 497\n",
      "192 of 497\n",
      "193 of 497\n",
      "194 of 497\n",
      "195 of 497\n",
      "196 of 497\n",
      "197 of 497\n",
      "198 of 497\n",
      "199 of 497\n",
      "200 of 497\n",
      "201 of 497\n",
      "202 of 497\n",
      "203 of 497\n",
      "204 of 497\n",
      "205 of 497\n",
      "206 of 497\n",
      "207 of 497\n",
      "208 of 497\n",
      "209 of 497\n",
      "210 of 497\n",
      "211 of 497\n",
      "212 of 497\n",
      "213 of 497\n",
      "214 of 497\n",
      "215 of 497\n",
      "216 of 497\n",
      "217 of 497\n",
      "218 of 497\n",
      "219 of 497\n",
      "220 of 497\n",
      "221 of 497\n",
      "222 of 497\n",
      "223 of 497\n",
      "224 of 497\n",
      "225 of 497\n",
      "226 of 497\n",
      "227 of 497\n",
      "228 of 497\n",
      "229 of 497\n",
      "230 of 497\n",
      "231 of 497\n",
      "232 of 497\n",
      "233 of 497\n",
      "234 of 497\n",
      "235 of 497\n",
      "236 of 497\n",
      "237 of 497\n",
      "238 of 497\n",
      "239 of 497\n",
      "240 of 497\n",
      "241 of 497\n",
      "242 of 497\n",
      "243 of 497\n",
      "244 of 497\n",
      "245 of 497\n",
      "246 of 497\n",
      "247 of 497\n",
      "248 of 497\n",
      "249 of 497\n",
      "250 of 497\n",
      "251 of 497\n",
      "252 of 497\n",
      "253 of 497\n",
      "254 of 497\n",
      "255 of 497\n",
      "256 of 497\n",
      "257 of 497\n",
      "258 of 497\n",
      "259 of 497\n",
      "260 of 497\n",
      "261 of 497\n",
      "262 of 497\n",
      "263 of 497\n",
      "264 of 497\n",
      "265 of 497\n",
      "266 of 497\n",
      "267 of 497\n",
      "268 of 497\n",
      "269 of 497\n",
      "270 of 497\n",
      "271 of 497\n",
      "272 of 497\n",
      "273 of 497\n",
      "274 of 497\n",
      "275 of 497\n",
      "276 of 497\n",
      "277 of 497\n",
      "278 of 497\n",
      "279 of 497\n",
      "280 of 497\n",
      "281 of 497\n",
      "282 of 497\n",
      "283 of 497\n",
      "284 of 497\n",
      "285 of 497\n",
      "286 of 497\n",
      "287 of 497\n",
      "288 of 497\n",
      "289 of 497\n",
      "290 of 497\n",
      "291 of 497\n",
      "292 of 497\n",
      "293 of 497\n",
      "294 of 497\n",
      "295 of 497\n",
      "296 of 497\n",
      "297 of 497\n",
      "298 of 497\n",
      "299 of 497\n",
      "300 of 497\n",
      "301 of 497\n",
      "302 of 497\n",
      "303 of 497\n",
      "304 of 497\n",
      "305 of 497\n",
      "306 of 497\n",
      "307 of 497\n",
      "308 of 497\n",
      "309 of 497\n",
      "310 of 497\n",
      "311 of 497\n",
      "312 of 497\n",
      "313 of 497\n",
      "314 of 497\n",
      "315 of 497\n",
      "316 of 497\n",
      "317 of 497\n",
      "318 of 497\n",
      "319 of 497\n",
      "320 of 497\n",
      "321 of 497\n",
      "322 of 497\n",
      "323 of 497\n",
      "324 of 497\n",
      "325 of 497\n",
      "326 of 497\n",
      "327 of 497\n",
      "328 of 497\n",
      "329 of 497\n",
      "330 of 497\n",
      "331 of 497\n",
      "332 of 497\n",
      "333 of 497\n",
      "334 of 497\n",
      "335 of 497\n",
      "336 of 497\n",
      "337 of 497\n",
      "338 of 497\n",
      "339 of 497\n",
      "340 of 497\n",
      "341 of 497\n",
      "342 of 497\n",
      "343 of 497\n",
      "344 of 497\n",
      "345 of 497\n",
      "346 of 497\n",
      "347 of 497\n",
      "348 of 497\n",
      "349 of 497\n",
      "350 of 497\n",
      "351 of 497\n",
      "352 of 497\n",
      "353 of 497\n",
      "354 of 497\n",
      "355 of 497\n",
      "356 of 497\n",
      "357 of 497\n",
      "358 of 497\n",
      "359 of 497\n",
      "360 of 497\n",
      "361 of 497\n",
      "362 of 497\n",
      "363 of 497\n",
      "364 of 497\n",
      "365 of 497\n",
      "366 of 497\n",
      "367 of 497\n",
      "368 of 497\n",
      "369 of 497\n",
      "370 of 497\n",
      "371 of 497\n",
      "372 of 497\n",
      "373 of 497\n",
      "374 of 497\n",
      "375 of 497\n",
      "376 of 497\n",
      "377 of 497\n",
      "378 of 497\n",
      "379 of 497\n",
      "380 of 497\n",
      "381 of 497\n",
      "382 of 497\n",
      "383 of 497\n",
      "384 of 497\n",
      "385 of 497\n",
      "386 of 497\n",
      "387 of 497\n",
      "388 of 497\n",
      "389 of 497\n",
      "390 of 497\n",
      "391 of 497\n",
      "392 of 497\n",
      "393 of 497\n",
      "394 of 497\n",
      "395 of 497\n",
      "396 of 497\n",
      "397 of 497\n",
      "398 of 497\n",
      "399 of 497\n",
      "400 of 497\n",
      "401 of 497\n",
      "402 of 497\n",
      "403 of 497\n",
      "404 of 497\n",
      "405 of 497\n",
      "406 of 497\n",
      "407 of 497\n",
      "408 of 497\n",
      "409 of 497\n",
      "410 of 497\n",
      "411 of 497\n",
      "412 of 497\n",
      "413 of 497\n",
      "414 of 497\n",
      "415 of 497\n",
      "416 of 497\n",
      "417 of 497\n",
      "418 of 497\n",
      "419 of 497\n",
      "420 of 497\n",
      "421 of 497\n",
      "422 of 497\n",
      "423 of 497\n",
      "424 of 497\n",
      "425 of 497\n",
      "426 of 497\n",
      "427 of 497\n",
      "428 of 497\n",
      "429 of 497\n",
      "430 of 497\n",
      "431 of 497\n",
      "432 of 497\n",
      "433 of 497\n",
      "434 of 497\n",
      "435 of 497\n",
      "436 of 497\n",
      "437 of 497\n",
      "438 of 497\n",
      "439 of 497\n",
      "440 of 497\n",
      "441 of 497\n",
      "442 of 497\n",
      "443 of 497\n",
      "444 of 497\n",
      "445 of 497\n",
      "446 of 497\n",
      "447 of 497\n",
      "448 of 497\n",
      "449 of 497\n",
      "450 of 497\n",
      "451 of 497\n",
      "452 of 497\n",
      "453 of 497\n",
      "454 of 497\n",
      "455 of 497\n",
      "456 of 497\n",
      "457 of 497\n",
      "458 of 497\n",
      "459 of 497\n",
      "460 of 497\n",
      "461 of 497\n",
      "462 of 497\n",
      "463 of 497\n",
      "464 of 497\n",
      "465 of 497\n",
      "466 of 497\n",
      "467 of 497\n",
      "468 of 497\n",
      "469 of 497\n",
      "470 of 497\n",
      "471 of 497\n",
      "472 of 497\n",
      "473 of 497\n",
      "474 of 497\n",
      "475 of 497\n",
      "476 of 497\n",
      "477 of 497\n",
      "478 of 497\n",
      "479 of 497\n",
      "480 of 497\n",
      "481 of 497\n",
      "482 of 497\n",
      "483 of 497\n",
      "484 of 497\n",
      "485 of 497\n",
      "486 of 497\n",
      "487 of 497\n",
      "488 of 497\n",
      "489 of 497\n",
      "490 of 497\n",
      "491 of 497\n",
      "492 of 497\n",
      "493 of 497\n",
      "494 of 497\n",
      "495 of 497\n",
      "496 of 497\n"
     ]
    }
   ],
   "source": [
    "def fetch_song(access_token, song_id):\n",
    "    url = f\"https://api.spotify.com/v1/tracks/{song_id}\"\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "def get_song_features(access_token, track_ids):\n",
    "    features_url = f\"https://api.spotify.com/v1/audio-features?ids={','.join(track_ids)}\"\n",
    "    header = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    res = requests.get(features_url, headers=header)\n",
    "    return res.json()\n",
    "\n",
    "song_details = []\n",
    "all_new_songs = pd.DataFrame()\n",
    "\n",
    "for i, song_id in enumerate(song_ids):\n",
    "    print(f\"{i} of {len(song_ids)}\")\n",
    "    \n",
    "    song_info = fetch_song(access_token, song_id)\n",
    "    detail = get_song_features(access_token, [song_id])[\"audio_features\"][0]\n",
    "        \n",
    "    if detail is not None and song_info is not None:\n",
    "        merged_song_detail = {**song_info, **detail}\n",
    "        song_details.append(merged_song_detail)\n",
    "\n",
    "songs_df = pd.DataFrame([{\n",
    "    'track_name': song.get('name', ''),\n",
    "    'artist(s)_name': \", \".join([artist['name'] for artist in song.get('artists', [])]),\n",
    "    'artist_count': len(song.get('artists')),\n",
    "    'album': song.get('album', {}).get('name', \"\"),\n",
    "    'explicit': song.get('explicit', ''),\n",
    "    'popularity': song.get('popularity', np.NaN),\n",
    "    'release_date': song.get('album', {}).get('release_date', \"\"),\n",
    "    'streams': np.NaN,\n",
    "    'duration_in_min': song.get('duration_ms', np.NaN) / 60000,\n",
    "    'bpm': math.floor(song['tempo']) if 'tempo' in song and song['tempo'] is not None else np.NaN,\n",
    "    'key': map_key_to_pitch_class(song.get('key', -1)),\n",
    "    'mode': map_mode_to_name(song.get('mode', np.NaN)),\n",
    "    'danceability_%': math.ceil(song.get('danceability', np.NaN) * 100) if 'danceability' in song and song['danceability'] is not None else np.NaN,\n",
    "    'valence_%': math.ceil(song.get('valence', np.NaN) * 100) if 'valence' in song and song['valence'] is not None else np.NaN,\n",
    "    'energy_%': math.ceil(song.get('energy', np.NaN) * 100) if 'energy' in song and song['energy'] is not None else np.NaN,\n",
    "    'acousticness_%': math.ceil(song.get('acousticness', np.NaN) * 100) if 'acousticness' in song and song['acousticness'] is not None else np.NaN,\n",
    "    'instrumentalness_%': math.ceil(song.get('instrumentalness', np.NaN) * 100) if 'instrumentalness' in song and song['instrumentalness'] is not None else np.NaN,\n",
    "    'liveness_%': math.ceil(song.get('liveness', np.NaN) * 100) if 'liveness' in song and song['liveness'] is not None else np.NaN,\n",
    "    'speechiness_%': math.ceil(song.get('speechiness', np.NaN) * 100) if 'speechiness' in song and song['speechiness'] is not None else np.NaN,\n",
    "} for song in song_details])\n",
    "\n",
    "all_new_songs = pd.concat(\n",
    "    [all_new_songs, songs_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist(s)_name</th>\n",
       "      <th>artist_count</th>\n",
       "      <th>album</th>\n",
       "      <th>explicit</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>streams</th>\n",
       "      <th>duration_in_min</th>\n",
       "      <th>bpm</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>danceability_%</th>\n",
       "      <th>valence_%</th>\n",
       "      <th>energy_%</th>\n",
       "      <th>acousticness_%</th>\n",
       "      <th>instrumentalness_%</th>\n",
       "      <th>liveness_%</th>\n",
       "      <th>speechiness_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D (feat. Jack Harlow)</td>\n",
       "      <td>Jung Kook, Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.363533</td>\n",
       "      <td>108</td>\n",
       "      <td>C#</td>\n",
       "      <td>Major</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Closer to You (feat. Major Lazer)</td>\n",
       "      <td>Jung Kook, Major Lazer</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.849917</td>\n",
       "      <td>113</td>\n",
       "      <td>D</td>\n",
       "      <td>Minor</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seven (feat. Latto) (Explicit Ver.)</td>\n",
       "      <td>Jung Kook, Latto</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059183</td>\n",
       "      <td>124</td>\n",
       "      <td>B</td>\n",
       "      <td>Major</td>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Standing Next to You</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>96</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.433667</td>\n",
       "      <td>106</td>\n",
       "      <td>D</td>\n",
       "      <td>Minor</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes or No</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.459283</td>\n",
       "      <td>83</td>\n",
       "      <td>C#</td>\n",
       "      <td>Major</td>\n",
       "      <td>68</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Please Don't Change (feat. DJ Snake)</td>\n",
       "      <td>Jung Kook, DJ Snake</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>87</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.444750</td>\n",
       "      <td>114</td>\n",
       "      <td>B</td>\n",
       "      <td>Major</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hate You</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570617</td>\n",
       "      <td>79</td>\n",
       "      <td>D</td>\n",
       "      <td>Major</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Somebody</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>106</td>\n",
       "      <td>C#</td>\n",
       "      <td>Minor</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>68</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Too Sad to Dance</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.931867</td>\n",
       "      <td>100</td>\n",
       "      <td>A#</td>\n",
       "      <td>Major</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shot Glass of Tears</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>1</td>\n",
       "      <td>GOLDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>86</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.787450</td>\n",
       "      <td>77</td>\n",
       "      <td>F#</td>\n",
       "      <td>Minor</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             track_name          artist(s)_name  artist_count  \\\n",
       "0                3D (feat. Jack Harlow)  Jung Kook, Jack Harlow             2   \n",
       "1     Closer to You (feat. Major Lazer)  Jung Kook, Major Lazer             2   \n",
       "2   Seven (feat. Latto) (Explicit Ver.)        Jung Kook, Latto             2   \n",
       "3                  Standing Next to You               Jung Kook             1   \n",
       "4                             Yes or No               Jung Kook             1   \n",
       "5  Please Don't Change (feat. DJ Snake)     Jung Kook, DJ Snake             2   \n",
       "6                              Hate You               Jung Kook             1   \n",
       "7                              Somebody               Jung Kook             1   \n",
       "8                      Too Sad to Dance               Jung Kook             1   \n",
       "9                   Shot Glass of Tears               Jung Kook             1   \n",
       "\n",
       "    album  explicit  popularity release_date  streams  duration_in_min  bpm  \\\n",
       "0  GOLDEN      True          85   2023-11-03      NaN         3.363533  108   \n",
       "1  GOLDEN     False          86   2023-11-03      NaN         2.849917  113   \n",
       "2  GOLDEN      True          87   2023-11-03      NaN         3.059183  124   \n",
       "3  GOLDEN     False          96   2023-11-03      NaN         3.433667  106   \n",
       "4  GOLDEN     False          88   2023-11-03      NaN         2.459283   83   \n",
       "5  GOLDEN     False          87   2023-11-03      NaN         2.444750  114   \n",
       "6  GOLDEN     False          88   2023-11-03      NaN         2.570617   79   \n",
       "7  GOLDEN     False          86   2023-11-03      NaN         2.810000  106   \n",
       "8  GOLDEN     False          86   2023-11-03      NaN         2.931867  100   \n",
       "9  GOLDEN     False          86   2023-11-03      NaN         2.787450   77   \n",
       "\n",
       "  key   mode  danceability_%  valence_%  energy_%  acousticness_%  \\\n",
       "0  C#  Major              86         89        83               4   \n",
       "1   D  Minor              79         50        66              12   \n",
       "2   B  Major              79         88        84              32   \n",
       "3   D  Minor              72         82        81               5   \n",
       "4  C#  Major              68         89        84              18   \n",
       "5   B  Major              80         77        75              17   \n",
       "6   D  Major              42         25        28              87   \n",
       "7  C#  Minor              65         26        68              29   \n",
       "8  A#  Major              56         57        47              62   \n",
       "9  F#  Minor              51         17        40              51   \n",
       "\n",
       "   instrumentalness_%  liveness_%  speechiness_%  \n",
       "0                   0           9             11  \n",
       "1                   1          11              5  \n",
       "2                   0           8              5  \n",
       "3                   0          34             10  \n",
       "4                   0           8              9  \n",
       "5                   1          17             18  \n",
       "6                   0          10              4  \n",
       "7                   0          14              5  \n",
       "8                   0          11              9  \n",
       "9                   0           9              4  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_new_songs.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_songs.to_csv('./data/tracks_long_tail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_albums.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_albums = pd.read_excel(\"./data/albums_niche.xlsx\")\n",
    "\n",
    "niche_albums['artist_name'] = niche_albums['artist_name'].str.lstrip('\\n')\n",
    "niche_albums['genres'] = niche_albums['genres'].str.lstrip('\\n')\n",
    "niche_albums['descriptors'] = niche_albums['descriptors'].str.lstrip('\\n')\n",
    "niche_albums['release_name'] = niche_albums['release_name'].str.lstrip('\\n')\n",
    "\n",
    "niche_albums['release_date'] = niche_albums['release_date'].apply(\n",
    "    lambda x: str(x).replace(\" 00:00:00\", \"\") if \"00:00:00\" in str(x) else x)\n",
    "\n",
    "niche_albums['descriptors'] = niche_albums['descriptors'].apply(\n",
    "    lambda x: str(x).replace(\"\\n\", \", \"))\n",
    "\n",
    "niche_albums['genres'] = niche_albums['genres'].apply(\n",
    "    lambda x: str(x).replace(\"\\n\", \", \"))\n",
    "\n",
    "\n",
    "niche_albums = niche_albums[niche_albums['descriptors'].notna()]\n",
    "\n",
    "niche_albums.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpopular_albums = pd.read_excel(\"./data/unpopular_albums_2023.xlsx\")\n",
    "\n",
    "unpopular_albums['artist_name'] = unpopular_albums['artist_name'].str.lstrip('\\n')\n",
    "unpopular_albums['genres'] = unpopular_albums['genres'].str.lstrip('\\n')\n",
    "unpopular_albums['descriptors'] = unpopular_albums['descriptors'].str.lstrip('\\n')\n",
    "unpopular_albums['release_name'] = unpopular_albums['release_name'].str.lstrip('\\n')\n",
    "\n",
    "unpopular_albums['release_date'] = unpopular_albums['release_date'].apply(\n",
    "    lambda x: str(x).replace(\" 00:00:00\", \"\") if \"00:00:00\" in str(x) else x)\n",
    "\n",
    "unpopular_albums['descriptors'] = unpopular_albums['descriptors'].apply(\n",
    "    lambda x: str(x).replace(\"\\n\", \", \"))\n",
    "\n",
    "unpopular_albums['genres'] = unpopular_albums['genres'].apply(\n",
    "    lambda x: str(x).replace(\"\\n\", \", \"))\n",
    "\n",
    "unpopular_albums = unpopular_albums[unpopular_albums['descriptors'].notna()]\n",
    "\n",
    "unpopular_albums.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them\n",
    "\n",
    "merged_df = pd.concat([niche_albums, unpopular_albums], ignore_index=True)\n",
    "\n",
    "unpopular_albums.to_csv('./data/albums_long_tail.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
